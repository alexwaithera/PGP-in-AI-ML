{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Airline_sentiment_ANW.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQIHn7cLz4V4"
      },
      "source": [
        "## NLP Project: Twitter US Airline Sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-K86yfO08Cn"
      },
      "source": [
        "## Data Description:\r\n",
        "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\")."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yniant-f1dyN"
      },
      "source": [
        "**Objective:**\r\n",
        "- To implement the techniques learnt as a part of the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4lSBBEl3t4H"
      },
      "source": [
        "## Alex N Waithera # Project #8 NLP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZTlumxp3_dk"
      },
      "source": [
        "## 1. Importing the libraries, loading dataset, printing shape of data & data description"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiNfl1v89mEU",
        "outputId": "19df81db-e1f3-4d2c-bb74-2cbf0fdc8325"
      },
      "source": [
        "## mounting the drive to be able to use the dataset stored in the dataset.\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2shX2ry7NiT",
        "outputId": "d7e6800e-9662-4f58-9342-22851baa3f02"
      },
      "source": [
        "# install and import necessary libraries.\r\n",
        "\r\n",
        "!pip install contractions\r\n",
        "import warnings\r\n",
        "warnings.filterwarnings('ignore')\r\n",
        "import re, string, unicodedata                       \r\n",
        "import contractions                                     \r\n",
        "from bs4 import BeautifulSoup                           \r\n",
        "\r\n",
        "import numpy as np                                   \r\n",
        "import pandas as pd                                     \r\n",
        "import nltk                                             \r\n",
        "\r\n",
        "nltk.download('stopwords')                             \r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('wordnet')\r\n",
        "\r\n",
        "from nltk.corpus import stopwords                      \r\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize \r\n",
        "from nltk.stem.wordnet import WordNetLemmatizer     "
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.48)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.1)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.1.7)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTR_fsqc8LAc"
      },
      "source": [
        "#Load dataset.\r\n",
        "dataset = pd.read_csv('/content/drive/My Drive/Colab Notebooks/Tweets.csv')"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knt0STKF99oq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "2ffe4235-4c88-45f3-fcd4-e9c5aa99c15d"
      },
      "source": [
        "# Check first five(5) rows of data.\r\n",
        "dataset.head()"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>airline</th>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <th>name</th>\n",
              "      <th>negativereason_gold</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>text</th>\n",
              "      <th>tweet_coord</th>\n",
              "      <th>tweet_created</th>\n",
              "      <th>tweet_location</th>\n",
              "      <th>user_timezone</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.703060e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>cairdin</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/24/2015 11:35</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>0.3486</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/24/2015 11:15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>0.6837</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>yvonnalynn</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/24/2015 11:15</td>\n",
              "      <td>Lets Play</td>\n",
              "      <td>Central Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Bad Flight</td>\n",
              "      <td>0.7033</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/24/2015 11:15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.703010e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Can't Tell</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>Virgin America</td>\n",
              "      <td>NaN</td>\n",
              "      <td>jnardino</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2/24/2015 11:14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Pacific Time (US &amp; Canada)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       tweet_id airline_sentiment  ...  tweet_location               user_timezone\n",
              "0  5.703060e+17           neutral  ...             NaN  Eastern Time (US & Canada)\n",
              "1  5.703010e+17          positive  ...             NaN  Pacific Time (US & Canada)\n",
              "2  5.703010e+17           neutral  ...       Lets Play  Central Time (US & Canada)\n",
              "3  5.703010e+17          negative  ...             NaN  Pacific Time (US & Canada)\n",
              "4  5.703010e+17          negative  ...             NaN  Pacific Time (US & Canada)\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0ozItxX-Paz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9abd9e-dd53-4655-8194-87f103a8e4d9"
      },
      "source": [
        "#Print shape of data \r\n",
        "dataset.shape"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2im1XRuu-lIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "842a7719-0082-492a-f91e-1a0b39c8e63d"
      },
      "source": [
        "# Dataset description \r\n",
        "dataset.describe()"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_id</th>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <th>retweet_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1.464000e+04</td>\n",
              "      <td>14640.000000</td>\n",
              "      <td>10522.000000</td>\n",
              "      <td>14640.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.692184e+17</td>\n",
              "      <td>0.900169</td>\n",
              "      <td>0.638298</td>\n",
              "      <td>0.082650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>7.791092e+14</td>\n",
              "      <td>0.162830</td>\n",
              "      <td>0.330440</td>\n",
              "      <td>0.745778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.675880e+17</td>\n",
              "      <td>0.335000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>5.685590e+17</td>\n",
              "      <td>0.692300</td>\n",
              "      <td>0.360600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.694780e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.670600</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>5.698902e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>5.703110e+17</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>44.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           tweet_id  ...  retweet_count\n",
              "count  1.464000e+04  ...   14640.000000\n",
              "mean   5.692184e+17  ...       0.082650\n",
              "std    7.791092e+14  ...       0.745778\n",
              "min    5.675880e+17  ...       0.000000\n",
              "25%    5.685590e+17  ...       0.000000\n",
              "50%    5.694780e+17  ...       0.000000\n",
              "75%    5.698902e+17  ...       0.000000\n",
              "max    5.703110e+17  ...      44.000000\n",
              "\n",
              "[8 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JurVgDMFAbyz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1502c523-5991-42f4-82e2-535e65531d4a"
      },
      "source": [
        "#print dataset columns\r\n",
        "dataset.columns"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
              "       'negativereason', 'negativereason_confidence', 'airline',\n",
              "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
              "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
              "       'tweet_location', 'user_timezone'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQrbRLc54TiD"
      },
      "source": [
        "## 2. Dropping all other columns except “text” and “airline_sentiment:\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlyPaXlv_kQ6"
      },
      "source": [
        "# Drop all other columns except \"text\" and \"airline_sentiment\"\r\n",
        "data = dataset.drop(['tweet_id', 'airline_sentiment_confidence', 'negativereason', 'negativereason_confidence', 'airline','airline_sentiment_gold', 'name', 'negativereason_gold', 'retweet_count', 'tweet_coord', 'tweet_created',\r\n",
        "'tweet_location', 'user_timezone'], axis=1)"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z9dkw41IBef6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a91f6440-d2da-4dca-adc9-ad7a3ae51636"
      },
      "source": [
        "#Check the shape of data \r\n",
        "data.shape"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDVGjC9zCFap",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "eb487c66-74bd-4f99-ec82-6519fb3caf19"
      },
      "source": [
        "#Print first five(5) rows of data\r\n",
        "data.head()"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                            text\n",
              "0           neutral                                                                                             @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                        @VirginAmerica plus you've added commercials to the experience... tacky.\n",
              "2           neutral                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
              "4          negative                                                                         @VirginAmerica and it's a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGncC2FyDTCQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cca15bfe-fe51-45ce-c445-029871500ac0"
      },
      "source": [
        "#Check for null values \r\n",
        "data.isnull().sum(axis=0)   "
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "airline_sentiment    0\n",
              "text                 0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SiqI8cVvDj5v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "42079c07-3e11-4d76-8269-acb6ffd777ef"
      },
      "source": [
        "# Display full dataframe information (Non-turncated Text column.)\r\n",
        "pd.set_option('display.max_colwidth', None)\r\n",
        "\r\n",
        "data.head() "
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp;amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                            text\n",
              "0           neutral                                                                                             @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                        @VirginAmerica plus you've added commercials to the experience... tacky.\n",
              "2           neutral                                                         @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse\n",
              "4          negative                                                                         @VirginAmerica and it's a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1z-X4vTgudC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfcf0874-7f47-4045-c38c-7ca4a4fd9d87"
      },
      "source": [
        "#Univariate analysis of the 'airline_sentiment' variable. \r\n",
        "print(data['airline_sentiment'].value_counts(normalize=True))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "negative    0.626913\n",
            "neutral     0.211680\n",
            "positive    0.161407\n",
            "Name: airline_sentiment, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B470LgVN5CaE"
      },
      "source": [
        "## 3.Text pre-processing: Data preparation.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7CPdUlHC795",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "689e7207-0f85-4e29-de4d-6ffb33ab47b4"
      },
      "source": [
        "#Html tag removal \r\n",
        "def strip_html(text):\r\n",
        "    soup = BeautifulSoup(text, \"html.parser\")\r\n",
        "    return soup.get_text()\r\n",
        "\r\n",
        "data['text'] = data['text'].apply(lambda x: strip_html(x))\r\n",
        "data.head()"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you've added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it's a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                        text\n",
              "0           neutral                                                                                         @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                    @VirginAmerica plus you've added commercials to the experience... tacky.\n",
              "2           neutral                                                     @VirginAmerica I didn't today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it's really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
              "4          negative                                                                     @VirginAmerica and it's a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMTIjjjokadT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ca517845-de99-40c6-86c0-d0f04948cbb1"
      },
      "source": [
        "# Replace contractions \r\n",
        "def replace_contractions(text):\r\n",
        "    \"\"\"Replace contractions in string of text\"\"\"\r\n",
        "    return contractions.fix(text)\r\n",
        "\r\n",
        "data['text'] = data['text'].apply(lambda x: replace_contractions(x))\r\n",
        "data.head()"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>@VirginAmerica plus you have added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>@VirginAmerica I did not today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces &amp; they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>@VirginAmerica and it is a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                         text\n",
              "0           neutral                                                                                          @VirginAmerica What @dhepburn said.\n",
              "1          positive                                                   @VirginAmerica plus you have added commercials to the experience... tacky.\n",
              "2           neutral                                                     @VirginAmerica I did not today... Must mean I need to take another trip!\n",
              "3          negative  @VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces & they have little recourse\n",
              "4          negative                                                                     @VirginAmerica and it is a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nI4x7xF8lGww",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "68b2f266-b742-4917-f0c7-b7a34ecd49ec"
      },
      "source": [
        "#Removal of special characters and punctuations\r\n",
        "def remove_special_characters(text):\r\n",
        "    #define the pattern to keep\r\n",
        "    pat = r'[^a-zA-z0-9.,!?/:;\\\"\\'\\s]' \r\n",
        "    return re.sub(pat, '', text)\r\n",
        "data['text'] = data['text'].apply(lambda x:  remove_special_characters(x))\r\n",
        "data.head(5)    "
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>VirginAmerica What dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>VirginAmerica plus you have added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>VirginAmerica I did not today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces  they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>VirginAmerica and it is a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                       text\n",
              "0           neutral                                                                                          VirginAmerica What dhepburn said.\n",
              "1          positive                                                  VirginAmerica plus you have added commercials to the experience... tacky.\n",
              "2           neutral                                                    VirginAmerica I did not today... Must mean I need to take another trip!\n",
              "3          negative  VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces  they have little recourse\n",
              "4          negative                                                                    VirginAmerica and it is a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH1mQyKP7KMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "97568789-cb51-4309-a9ff-1ec9483d60ab"
      },
      "source": [
        "#Removal of URls\r\n",
        "data['text'] = data['text'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\r\n",
        "data['text'].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))\r\n",
        "data.head(5)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>VirginAmerica What dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>VirginAmerica plus you have added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>VirginAmerica I did not today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces  they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>VirginAmerica and it is a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                       text\n",
              "0           neutral                                                                                          VirginAmerica What dhepburn said.\n",
              "1          positive                                                  VirginAmerica plus you have added commercials to the experience... tacky.\n",
              "2           neutral                                                    VirginAmerica I did not today... Must mean I need to take another trip!\n",
              "3          negative  VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces  they have little recourse\n",
              "4          negative                                                                    VirginAmerica and it is a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUe2mjLJ-lEg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "95d69777-cd20-422c-f75f-34ee09ded109"
      },
      "source": [
        "#Removal of numbers.\r\n",
        "def remove_numbers(text):\r\n",
        "  text = re.sub(r'\\d+', '', text)\r\n",
        "  return text\r\n",
        "\r\n",
        "data['text'] = data['text'].apply(lambda x: remove_numbers(x))\r\n",
        "data.head(5)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>VirginAmerica What dhepburn said.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>VirginAmerica plus you have added commercials to the experience... tacky.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>VirginAmerica I did not today... Must mean I need to take another trip!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces  they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>VirginAmerica and it is a really big bad thing about it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                       text\n",
              "0           neutral                                                                                          VirginAmerica What dhepburn said.\n",
              "1          positive                                                  VirginAmerica plus you have added commercials to the experience... tacky.\n",
              "2           neutral                                                    VirginAmerica I did not today... Must mean I need to take another trip!\n",
              "3          negative  VirginAmerica it is really aggressive to blast obnoxious \"entertainment\" in your guests' faces  they have little recourse\n",
              "4          negative                                                                    VirginAmerica and it is a really big bad thing about it"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ioePSsq5eph",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "774d9b8f-ff7d-4fe0-afd3-36f7922c0f3b"
      },
      "source": [
        "#Tokenization of data\r\n",
        "# Tokenize the words of whole dataframe.\r\n",
        "for i, row in data.iterrows():\r\n",
        "    text = data.at[i, 'text']\r\n",
        "    words = nltk.word_tokenize(text)\r\n",
        "    data.at[i,'text'] = words\r\n",
        "data.head()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>[VirginAmerica, What, dhepburn, said, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>[VirginAmerica, plus, you, have, added, commercials, to, the, experience, ..., tacky, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>[VirginAmerica, I, did, not, today, ..., Must, mean, I, need, to, take, another, trip, !]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>[VirginAmerica, it, is, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, they, have, little, recourse]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>[VirginAmerica, and, it, is, a, really, big, bad, thing, about, it]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                                                text\n",
              "0           neutral                                                                                                            [VirginAmerica, What, dhepburn, said, .]\n",
              "1          positive                                                            [VirginAmerica, plus, you, have, added, commercials, to, the, experience, ..., tacky, .]\n",
              "2           neutral                                                           [VirginAmerica, I, did, not, today, ..., Must, mean, I, need, to, take, another, trip, !]\n",
              "3          negative  [VirginAmerica, it, is, really, aggressive, to, blast, obnoxious, ``, entertainment, '', in, your, guests, ', faces, they, have, little, recourse]\n",
              "4          negative                                                                                 [VirginAmerica, and, it, is, a, really, big, bad, thing, about, it]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgRl3XTbzVyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85085b95-181c-4a93-db90-b3c4ea049c31"
      },
      "source": [
        "# Removal of stopwords from the tokens\r\n",
        "all_stopwords = stopwords.words('english')\r\n",
        "all_stopwords.remove('not')\r\n",
        "\r\n",
        "text_tokens = word_tokenize(text)\r\n",
        "tokens_without_sw = [word for word in text_tokens if not word in all_stopwords]\r\n",
        "\r\n",
        "print(tokens_without_sw)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['AmericanAir', 'ppl', 'need', 'know', 'many', 'seats', 'next', 'flight', '.', 'Plz', 'put', 'us', 'standby', 'people', 'next', 'flight', '?']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tIn-0lPOimj"
      },
      "source": [
        "# Lemmatization and normalization of the tokenized words \r\n",
        "lemmatizer = WordNetLemmatizer()\r\n",
        "\r\n",
        "def remove_non_ascii(words):\r\n",
        "    \"\"\"Remove non-ASCII characters from list of tokenized words\"\"\"\r\n",
        "    new_words = []\r\n",
        "    for word in words:\r\n",
        "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\r\n",
        "        new_words.append(new_word)\r\n",
        "    return new_words\r\n",
        "\r\n",
        "def to_lowercase(words):\r\n",
        "    \"\"\"Convert all characters to lowercase from list of tokenized words\"\"\"\r\n",
        "    new_words = []\r\n",
        "    for word in words:\r\n",
        "        new_word = word.lower()\r\n",
        "        new_words.append(new_word)\r\n",
        "    return new_words\r\n",
        "\r\n",
        "def remove_punctuation(words):\r\n",
        "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\r\n",
        "    new_words = []\r\n",
        "    for word in words:\r\n",
        "        new_word = re.sub(r'[^\\w\\s]', '', word)\r\n",
        "        if new_word != '':\r\n",
        "            new_words.append(new_word)\r\n",
        "    return new_words\r\n",
        "\r\n",
        "def remove_stopwords(words):\r\n",
        "    \"\"\"Remove stop words from list of tokenized words\"\"\"\r\n",
        "    new_words = []\r\n",
        "    for word in words:\r\n",
        "        if word not in tokens_without_sw:\r\n",
        "            new_words.append(word)\r\n",
        "    return new_words\r\n",
        "\r\n",
        "def lemmatize_list(words):\r\n",
        "    new_words = []\r\n",
        "    for word in words:\r\n",
        "      new_words.append(lemmatizer.lemmatize(word, pos='v'))\r\n",
        "    return new_words\r\n",
        "\r\n",
        "def normalize(words):\r\n",
        "    words = remove_non_ascii(words)\r\n",
        "    words = to_lowercase(words)\r\n",
        "    words = remove_punctuation(words)\r\n",
        "    words = remove_stopwords(words)\r\n",
        "    words = lemmatize_list(words)\r\n",
        "    return ' '.join(words)\r\n"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "0SgG_mdNvYa4",
        "outputId": "67b2d807-dff0-4b2f-fb77-2e6d1b0af6e4"
      },
      "source": [
        "# Join the words in the list to convert back to text string in the dataframe. (So that each row contains the data in text format.)\r\n",
        "data['text'] = data.apply(lambda row: normalize(row['text']), axis=1)\r\n",
        "data.head(10)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline_sentiment</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>neutral</td>\n",
              "      <td>virginamerica what dhepburn say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>positive</td>\n",
              "      <td>virginamerica plus you have add commercials to the experience tacky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>neutral</td>\n",
              "      <td>virginamerica i do not today must mean i to take another trip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>negative</td>\n",
              "      <td>virginamerica it be really aggressive to blast obnoxious entertainment in your guests face they have little recourse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>negative</td>\n",
              "      <td>virginamerica and it be a really big bad thing about it</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>negative</td>\n",
              "      <td>virginamerica seriously would pay a for that do not have this play it be really the only bad thing about fly va</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>positive</td>\n",
              "      <td>virginamerica yes nearly every time i fly vx this ear worm will not go away</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>neutral</td>\n",
              "      <td>virginamerica really miss a prime opportunity for men without hat parody there</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>positive</td>\n",
              "      <td>virginamerica well i do notbut now i do d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>positive</td>\n",
              "      <td>virginamerica it be amaze and arrive an hour early you be too good to me</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline_sentiment                                                                                                                  text\n",
              "0           neutral                                                                                       virginamerica what dhepburn say\n",
              "1          positive                                                   virginamerica plus you have add commercials to the experience tacky\n",
              "2           neutral                                                         virginamerica i do not today must mean i to take another trip\n",
              "3          negative  virginamerica it be really aggressive to blast obnoxious entertainment in your guests face they have little recourse\n",
              "4          negative                                                               virginamerica and it be a really big bad thing about it\n",
              "5          negative       virginamerica seriously would pay a for that do not have this play it be really the only bad thing about fly va\n",
              "6          positive                                           virginamerica yes nearly every time i fly vx this ear worm will not go away\n",
              "7           neutral                                        virginamerica really miss a prime opportunity for men without hat parody there\n",
              "8          positive                                                                             virginamerica well i do notbut now i do d\n",
              "9          positive                                              virginamerica it be amaze and arrive an hour early you be too good to me"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUDzkOHc6DS8"
      },
      "source": [
        "## 4. Vectorization.\r\n",
        "### a) Using CountVectorizer for Vectorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6iqg-_pPhTC"
      },
      "source": [
        "# Vectorization (Convert text data to numbers).\r\n",
        "from sklearn.feature_extraction.text import CountVectorizer\r\n",
        "\r\n",
        "vectorizer = CountVectorizer(max_features=2500)              \r\n",
        "data_features = vectorizer.fit_transform(data['text'])\r\n",
        "\r\n",
        "data_features = data_features.toarray()  "
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEBYf5umP4O7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12d50921-eb2c-48bb-cdab-cdd6a5846509"
      },
      "source": [
        "data_features.shape"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 2500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o01v776tXrfp"
      },
      "source": [
        "### b) Using TfidfVectorizer for Vectorization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ur4or7JUXxux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e17f805-76b6-4099-faa8-52f1c7e148fc"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\r\n",
        "# create the transform\r\n",
        "vectorizer = TfidfVectorizer(max_features=2500)\r\n",
        "# encode document\r\n",
        "vector = vectorizer.fit_transform(data['text'])\r\n",
        "# summarize encoded vector\r\n",
        "print(vector.shape)\r\n",
        "print(vector.toarray())"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14640, 2500)\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBHk7zF_6PW0"
      },
      "source": [
        "##5. Fitting and evaluating model using both type of vectorization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DEZaP6R3rtN1"
      },
      "source": [
        "### a) Applying CountVectorizer to fit and evaluate the Random Forest Classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ND9Snuuu79yF"
      },
      "source": [
        "# Labels \r\n",
        "y = pd.get_dummies(data['airline_sentiment']).values\r\n",
        "X = data_features\r\n",
        "y = y.astype('int')\r\n",
        "y =data['airline_sentiment']"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLjHyYbV7-Zh",
        "outputId": "c3f250f1-95c2-43cc-d980-0f0317527421"
      },
      "source": [
        "# Split data into training and testing set.\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\r\n",
        "print(X_train.shape)\r\n",
        "print(y_train.shape)"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10980, 2500)\n",
            "(10980,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0_uEQPeCLRl"
      },
      "source": [
        "# standardization\r\n",
        "from sklearn.preprocessing import StandardScaler\r\n",
        "\r\n",
        "sc = StandardScaler()\r\n",
        "\r\n",
        "X_train = sc.fit_transform(X_train)\r\n",
        "X_test = sc.transform(X_test)"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nz8iVKA4w3GZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "804ec9ac-2530-449d-e6db-51fef7b88017"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "forest = RandomForestClassifier(n_estimators=10, n_jobs=4)\r\n",
        "\r\n",
        "forest = forest.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(forest)\r\n",
        "\r\n",
        "print(np.mean(cross_val_score(forest, data_features, y, cv=20)))\r\n"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "                       oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "0.7354508196721311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Utc3tBn4Y1O"
      },
      "source": [
        "# Predicting using the model for X_test data.\r\n",
        "\r\n",
        "Y_pred_class = forest.predict(X_test)"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaEbFC6O7l9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66b653c-f910-4ddb-9b26-6a40c0adaffa"
      },
      "source": [
        "num_classes = 3\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\r\n",
        "print(classification_report(y_test, Y_pred_class, target_names=target_names))"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.80      0.93      0.86      2340\n",
            "     Class 1       0.61      0.46      0.52       738\n",
            "     Class 2       0.80      0.49      0.61       582\n",
            "\n",
            "    accuracy                           0.77      3660\n",
            "   macro avg       0.74      0.63      0.66      3660\n",
            "weighted avg       0.76      0.77      0.75      3660\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_TziaItXhoK"
      },
      "source": [
        "### b) Applying TfidfVectorizer to fit and evaluate the Random Forest Classifier.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7aSluh_afgo"
      },
      "source": [
        "X = vector"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMzkLgEwa7uv"
      },
      "source": [
        "# Split data into training and testing set.\r\n",
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PMqqOIpubJuB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d800782-0eb5-4809-c8ca-09189694883a"
      },
      "source": [
        "# Using Random Forest to build model for the classification of sentiment analysis.\r\n",
        "# Also calculating the cross validation score.\r\n",
        "\r\n",
        "from sklearn.ensemble import RandomForestClassifier\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "forest_vector = RandomForestClassifier(n_estimators=10, n_jobs=4)\r\n",
        "\r\n",
        "forest_vector = forest.fit(X_train, y_train)\r\n",
        "\r\n",
        "print(forest_vector)\r\n",
        "\r\n",
        "print(np.mean(cross_val_score(forest, vector, y, cv=20)))"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=4,\n",
            "                       oob_score=False, random_state=None, verbose=0,\n",
            "                       warm_start=False)\n",
            "0.7286885245901639\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdfuO8VxQLpY"
      },
      "source": [
        "# Predicting using the model for X_test data.\r\n",
        "\r\n",
        "Y_pred_class2 = forest.predict(X_test)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_R7x6enQwQ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9abb5177-1af9-4dfa-ba25-f71380662dd8"
      },
      "source": [
        "num_classes = 3\r\n",
        "from sklearn.metrics import classification_report\r\n",
        "target_names = [\"Class {}\".format(i) for i in range(num_classes)]\r\n",
        "print(classification_report(y_test, Y_pred_class2, target_names=target_names))"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.79      0.95      0.86      2340\n",
            "     Class 1       0.63      0.42      0.51       738\n",
            "     Class 2       0.81      0.48      0.61       582\n",
            "\n",
            "    accuracy                           0.77      3660\n",
            "   macro avg       0.74      0.62      0.66      3660\n",
            "weighted avg       0.76      0.77      0.75      3660\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kma1UKU16b4j"
      },
      "source": [
        "##6. Summarize your understanding of the application of various Pre-processing and Vectorization and performance of your model on this dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atBDANUOX_KB"
      },
      "source": [
        "- The objective of this project was to implement the concepts and techniques of Natural Language Processing (NLP) as learnt in the course. A sentiment analysis was conducted to classify the sentiment of tweets as positive, negative or neutral. \r\n",
        "- The learning outcomes of the project were: \r\n",
        "a) Basic understanding of text pre-processing\r\n",
        "b) What to do after text pre-processing: i.e. Bag of words & Tfidf \r\n",
        "c) Build the classification model. \r\n",
        "d) Evaluate the Model. \r\n",
        "\r\n",
        "Consequently, these outcomes were achieved successfully as follows:  \r\n",
        "\r\n",
        "First, various pre-processing techniques learnt in the course were applied to the dataset which initially contained 14,640 rows and 15 columns. However, all other columns were dropped except “text” and “airline_sentiment” which were the focus of our sentiment analysis. \r\n",
        "\r\n",
        "Second, the dataset was analysed to check whether there were null values, but none were found. Also, the data distribution of the “airline_sentiment\" column was done to check for any data imbalances that might affect the final model. However, no artificial data was added using SMOTE because the target variable seem to be well distributed. There are no minority classess as such. Below are the results of the analysis as captured: \r\n",
        "    - negative    0.626913\r\n",
        "    - neutral     0.211680\r\n",
        "    - positive    0.161407\r\n",
        "\r\n",
        "\r\n",
        "Third, application of various data pre-processing steps was conducted mainly for our dependent variable which in this case is the twitter text i.e. data['text']. Viewing at the twitter text, there were various punctuation marks, numbers, emoji characters, stopwords, non-ASCII characters, URLs, HTML tags etc. As a result, various techniques were applied as captured in section three(3) above to clean the twitter text and remove all unnecessary noise in the text data. \r\n",
        "\r\n",
        "Four, tokenization was applied to the text data where the different tweet texts were broken down to tokens - breaking text into tokens which is called tokenization. In addition, after tokenization was applied, the different texts were reduced to a core root and in this case lemmatization was preferred instead of stemming to maintain the dictionary form of the words. \r\n",
        "\r\n",
        "Five, after tokenization, lemmatization and removal of stopwords, the words were normalized and joined together before ready vectorization. Vectorization was conducted to create a sparse -term-document matrix as shown in section four (4) above, applying both countvectorizer and TfidfVectorizer.\r\n",
        "\r\n",
        "Six, vectorization involved converting the tweet text data into a numerical sparse matrix to form our X variable or numeric vector which was fed into the model (Random Forest Classiffier) to predict our target variable (y). Our target variable y has three(3) classifications i.e. negative, neural and positive, depending on how the words are read by the model. Our target variable (y) was also converted to a numerical form (class 0, class 1, and class 2) through one-hot-encoding, before it was fed into the classification model. Based on the results, class 0 represent negative sentiments, class 1 represent neutral setiments and class 2 represent positive sentiments. \r\n",
        "\r\n",
        "Seven, both forms of the vectorized data (X_variable) i.e. Countvectorizer and TfidfVectorizer resulting from the tweet text were fitted into the Random Forest Classifier. The training data from both models yielded an accuracy of about 73% while the test data yielded a model accuracy of 77% for both models i.e. either applying Countvectorizer or TfidfVectorizer vectorization. Please see the classsification or confusion matrix produced in section five (5) above.  \r\n",
        "\r\n",
        "In conclusion, sentiment analysis such as classifying the sentiments of tweets as positive or negative or neutral can be implemented successfully using techniques of NLP as captured above. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X80sp-IY66kz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}